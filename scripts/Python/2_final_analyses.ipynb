{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ecc7714",
   "metadata": {},
   "source": [
    "# Load packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4a72bd-8d68-4a8f-ad38-e30f19926b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import gpboost\n",
    "import gpboost as gpb\n",
    "\n",
    "class GPBoostClassifier:\n",
    "    def __init__(self,scan=False,use_coords=False,random_state=42,boosting_type='gbdt'):\n",
    "        self.scan=scan\n",
    "        self.use_coords=use_coords\n",
    "        self.random_state=random_state\n",
    "        self.boosting_type=boosting_type\n",
    "    \n",
    "    def fit(self,X,y,groups,coords=None):\n",
    "        data_train = gpb.Dataset(X, y)\n",
    "        self.gp_model = gpb.GPModel(group_data=groups, likelihood=\"bernoulli_logit\", gp_coords=coords.values if self.use_coords else None,cov_function=\"exponential\")\n",
    "        params = {'learning_rate': 1e-1, 'min_data_in_leaf': 20, 'objective': \"binary\",\n",
    "                  'verbose': 0}\n",
    "        if self.boosting_type!='gbdt':\n",
    "            assert self.boosting_type in ['rf','dart']\n",
    "            params['boosting']=self.boosting_type\n",
    "        num_boost_round = 300\n",
    "        \n",
    "        if self.scan:\n",
    "            param_grid_small = {'learning_rate': [0.1,0.01,0.001], 'min_data_in_leaf': [20,50,100],\n",
    "                                'max_depth': [5,10,15], 'max_bin': [255,1000], 'use_nesterov_acc': [False,True]}\n",
    "            opt_params = gpb.grid_search_tune_parameters(param_grid=param_grid_small,\n",
    "                                                         params=params,\n",
    "                                                         num_try_random=15,\n",
    "                                                         folds=list(GroupShuffleSplit(random_state=42).split(X,y,groups)),\n",
    "                                                         gp_model=self.gp_model,\n",
    "                                                         use_gp_model_for_validation=True,\n",
    "                                                         train_set=data_train,\n",
    "                                                         verbose_eval=1,\n",
    "                                                         num_boost_round=num_boost_round,#50 \n",
    "                                                         early_stopping_rounds=10,\n",
    "                                                         seed=1,\n",
    "                                                         metrics='binary_logloss') \n",
    "\n",
    "            params=opt_params['best_params']\n",
    "\n",
    "        self.gpm = gpb.train(params=params,\n",
    "                    train_set=data_train,\n",
    "                    gp_model=self.gp_model,\n",
    "                    num_boost_round=num_boost_round,\n",
    "                   )\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self,X,groups,coords=None):\n",
    "        y_pred = self.gpm.predict(data=X, group_data_pred=groups, gp_coords_pred=coords.values if self.use_coords else None,\n",
    "                            predict_var=True, raw_score=False)['response_mean']\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f58d120-868e-41a6-8e10-87b6ecc98890",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_pickle(\"../../data/final_splits.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad3d9a2",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a7f38a-f85f-43d8-8db5-ecff0304f92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=dict()\n",
    "for k in data:\n",
    "    results[k]=dict()\n",
    "    for cv_idx in range(10):\n",
    "        train_idx,test_idx=data[k]['splits'].iloc[:,cv_idx],(~data[k]['splits'].iloc[:,cv_idx])\n",
    "        rf=XGBClassifier(random_state=42).fit(data[k]['X'].loc[train_idx],data[k]['y'].loc[train_idx])\n",
    "        y_pred=rf.predict_proba(data[k]['X'].loc[test_idx])[:,1]\n",
    "        results[k][cv_idx+1]=dict(y_pred=y_pred,\n",
    "                              y_true=data[k]['y'].loc[test_idx].astype(float))\n",
    "pickle.dump(results,open(\"../../results/xgboost.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1c3afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainers_xg=dict()\n",
    "shap_vals_xg=dict()\n",
    "shap_interactions_xg=dict()\n",
    "\n",
    "for k in data:\n",
    "    rf=XGBClassifier(random_state=42).fit(data[k]['X'],data[k]['y'])\n",
    "    explainers_xg[k]=shap.TreeExplainer(rf)\n",
    "    shap_vals_xg[k] = explainers_xg[k].shap_values(data[k]['X'])\n",
    "    shap_interactions_xg[k]=explainers_xg[k].shap_interaction_values(data[k]['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1643e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=\"mets_intra\"\n",
    "shap.summary_plot(shap_vals_xg[k], data[k][\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4649d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=\"mets_away\"\n",
    "shap.summary_plot(shap_vals_xg[k], data[k][\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c2794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=\"macro_ws\"\n",
    "shap.summary_plot(shap_vals_xg[k], data[k][\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcf7631",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=\"mets_overall\"\n",
    "shap.dependence_plot(\"CD20\", shap_vals_xg[k], data[k][\"X\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ef5ef5",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326c0633-9257-4ffd-ba4e-d0e916307068",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=dict()\n",
    "for k in data:\n",
    "    results[k]=dict()\n",
    "    for cv_idx in range(10):\n",
    "        train_idx,test_idx=data[k]['splits'].iloc[:,cv_idx],(~data[k]['splits'].iloc[:,cv_idx])\n",
    "        rf=RandomForestClassifier(random_state=42).fit(data[k]['X'].loc[train_idx],data[k]['y'].loc[train_idx])\n",
    "        y_pred=rf.predict_proba(data[k]['X'].loc[test_idx])[:,1]\n",
    "        results[k][cv_idx+1]=dict(y_pred=y_pred,\n",
    "                              y_true=data[k]['y'].loc[test_idx].astype(float))\n",
    "pickle.dump(results,open(\"../../results/rf.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5ee306",
   "metadata": {},
   "source": [
    "# GPBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d0b027-21e6-4d01-a2d4-541f23b3f27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "results=dict()\n",
    "for k in data:\n",
    "    results[k]=dict()\n",
    "    for cv_idx in range(10):\n",
    "        np.random.seed(42)\n",
    "        train_idx,test_idx=data[k]['splits'].iloc[:,cv_idx],(~data[k]['splits'].iloc[:,cv_idx])\n",
    "        gpc=GPBoostClassifier(random_state=42).fit(data[k]['X'].loc[train_idx],data[k]['y'].loc[train_idx],data[k]['group'].loc[train_idx])\n",
    "        y_pred=gpc.predict_proba(data[k]['X'].loc[test_idx],data[k]['group'].loc[test_idx])\n",
    "        results[k][cv_idx+1]=dict(y_pred=y_pred,\n",
    "                              y_true=data[k]['y'].loc[test_idx].astype(float))\n",
    "pickle.dump(results,open(\"../../results/gpb.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d0540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainers=dict()\n",
    "shap_vals=dict()\n",
    "shap_interactions=dict()\n",
    "\n",
    "for k in data:\n",
    "    gpc=GPBoostClassifier(random_state=42).fit(data[k]['X'],data[k]['y'],data[k]['group'])\n",
    "    explainers[k]=shap.TreeExplainer(gpc.gpm)\n",
    "    shap_vals[k] = explainers[k].shap_values(data[k]['X'],data[k]['group'])\n",
    "    shap_interactions[k]=explainers[k].shap_interaction_values(data[k]['X'],data[k]['group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d3a456",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=\"macro_ws\"\n",
    "shap.dependence_plot(\"CTLA4\", shap_vals[k], data[k][\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d633db94",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=\"mets_intra\"\n",
    "shap.summary_plot(shap_vals[k], data[k][\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4dcad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=\"mets_overall\"\n",
    "shap.summary_plot(shap_vals[k], data[k][\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01be8ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=\"macro_ws\"\n",
    "shap.summary_plot(shap_vals[k], data[k][\"X\"], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb16bc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib,matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['figure.dpi']=300\n",
    "k=\"mets_overall\"\n",
    "shap.dependence_plot(\"CD20\", shap_vals[k], data[k][\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf78f534",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=\"mets_intra\"\n",
    "shap.dependence_plot(\"CD8\", shap_vals[k], data[k][\"X\"], interaction_index=\"CD45\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b027b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=\"mets_inter\"\n",
    "shap.dependence_plot(\"CTLA4\", shap_vals[k], data[k][\"X\"], interaction_index=\"CD68\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd911dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=\"macro_ws\"\n",
    "shap.dependence_plot(\"CD68\", shap_vals[k], data[k][\"X\"], interaction_index=\"PanCk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a6987",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=\"macro_ws\"\n",
    "shap.dependence_plot(\"CD34\", shap_vals[k], data[k][\"X\"], interaction_index=\"PanCk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15017c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"Beta_2_microglobulin\", shap_vals[k], data[k][\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ca8544",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=\"mets_inter\"\n",
    "shap.dependence_plot(\"CD68\", shap_vals[k], data[k][\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9d4b2c-c811-4f67-9d57-da728d375fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=dict()\n",
    "for k in data:\n",
    "    if \"macro\" in k:\n",
    "        if k not in list(results.keys()): results[k]=dict()\n",
    "        for cv_idx in range(10):\n",
    "            np.random.seed(42)\n",
    "            if (cv_idx+1) not in list(results[k].keys()):\n",
    "                print(k,cv_idx+1)\n",
    "                train_idx,test_idx=data[k]['splits'].iloc[:,cv_idx],(~data[k]['splits'].iloc[:,cv_idx])\n",
    "                rf=GPBoostClassifier(random_state=42,use_coords=True).fit(data[k]['X'].loc[train_idx],data[k]['y'].loc[train_idx],data[k]['group'].loc[train_idx],coords=data[k]['coords'].loc[train_idx])\n",
    "                y_pred=rf.predict_proba(data[k]['X'].loc[test_idx],data[k]['group'].loc[test_idx],coords=data[k]['coords'].loc[test_idx])\n",
    "                results[k][cv_idx+1]=dict(y_pred=y_pred,\n",
    "                                      y_true=data[k]['y'].loc[test_idx].astype(float))\n",
    "pickle.dump(results,open(\"../../results/gpb_coords.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19586421",
   "metadata": {},
   "source": [
    "# Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4dcb28-bfd5-460a-98b1-27e5306b3150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "interactions_dict=dict()\n",
    "for k in data:\n",
    "    interactions_dict[k]=dict()\n",
    "    for cv_idx in range(10):\n",
    "        print(k,cv_idx)\n",
    "        np.random.seed(42)\n",
    "        train_idx,test_idx=data[k]['splits'].iloc[:,cv_idx],(~data[k]['splits'].iloc[:,cv_idx])\n",
    "        gpc=GPBoostClassifier(random_state=42).fit(data[k]['X'].loc[train_idx],data[k]['y'].loc[train_idx],data[k]['group'].loc[train_idx])\n",
    "        explainer=shap.TreeExplainer(gpc.gpm)\n",
    "        shap_values = explainer.shap_values(data[k]['X'].loc[train_idx],data[k]['group'].loc[train_idx])\n",
    "        interaction_val=explainer.shap_interaction_values(data[k]['X'].loc[train_idx])\n",
    "        interactions=np.abs(interaction_val).sum(0)\n",
    "        interactions[np.eye(*interactions.shape).astype(bool)]=0\n",
    "        interactions=pd.DataFrame(interactions,columns=data[k]['X'].columns,index=data[k]['X'].columns)\n",
    "        interactions_dict[k][cv_idx+1]=interactions\n",
    "pickle.dump(interactions_dict,open('../../interactions/interactions.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ee9413",
   "metadata": {},
   "source": [
    "# Output GPBoost interactions to R BGLMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fcdd54-3656-41f9-8d98-b173de3a97b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "interactions_dict=pd.read_pickle('../../interactions/interactions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac63ecc-55f8-43f2-9507-f41e327d12ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for k in data:\n",
    "    all_interaction_shap_scores=reduce(lambda x,y:x+y,list(interactions_dict[k].values())).where(np.triu(np.ones(interactions_dict[k][1].shape),k=1).astype(np.bool)).stack().reset_index()\n",
    "    all_interaction_shap_scores.columns=['feature_1','feature_2', 'shap_interaction_score']\n",
    "    all_interaction_shap_scores=all_interaction_shap_scores.sort_values('shap_interaction_score',ascending=False)\n",
    "    print(k,'      ','+'.join([':'.join(x) for x in all_interaction_shap_scores.iloc[:10,:2].values.tolist()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547696e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_vals_df=dict()\n",
    "for k in data:\n",
    "    all_interaction_shap_scores=reduce(lambda x,y:x+y,list(interactions_dict[k].values())).where(np.triu(np.ones(interactions_dict[k][1].shape),k=1).astype(np.bool)).stack().reset_index()\n",
    "    all_interaction_shap_scores.columns=['feature_1','feature_2', 'shap_interaction_score']\n",
    "    shap_vals_df[k]=all_interaction_shap_scores.sort_values('shap_interaction_score',ascending=False).iloc[:10,:2].apply(lambda x: \":\".join(x),axis=1).reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_2",
   "language": "python",
   "name": "py37_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
