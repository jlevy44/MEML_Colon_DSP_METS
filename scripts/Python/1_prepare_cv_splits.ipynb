{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit,StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=dict()\n",
    "\n",
    "for k in ['hk','igg']:\n",
    "    data=pd.read_pickle(\"../../data/dsp_data_expr.pkl\")[k]\n",
    "\n",
    "    data['pheno']['sex']=(data['pheno']['sex']==\"M\").astype(float)\n",
    "    any_mets=data['pheno']['any_mets']\n",
    "    batch=data['pheno']['batch']\n",
    "    macro_annot=data['pheno']['macro_annot']\n",
    "    macro_annot_coded=pd.get_dummies(macro_annot)[['intra','inter']]\n",
    "    macro_annot=macro_annot.map(dict(intra=0,inter=1,away=2))\n",
    "    X=pd.concat([data['expr'],data['pheno'][['age','sex']],macro_annot_coded],axis=1)\n",
    "    data['pheno']=pd.concat([data['pheno'],macro_annot_coded],axis=1)\n",
    "    patient=data['pheno']['patient_id']\n",
    "\n",
    "\n",
    "    data['cv_splits_mets']=pd.DataFrame(index=data['pheno'].index)\n",
    "    data['cv_splits_macro']=pd.DataFrame(index=data['pheno'].index)\n",
    "    data['cv_splits_macro_batch']=pd.DataFrame(index=data['pheno'].index)\n",
    "    \n",
    "    data['xy']=data['pheno'][['roi_x','roi_y']]\n",
    "\n",
    "    ss=GroupShuffleSplit(n_splits=10, random_state=42, test_size=None,\n",
    "                train_size=0.7)\n",
    "\n",
    "    for i,(train_idx,test_idx) in enumerate(list(ss.split(X=X,y=any_mets,groups=batch))):\n",
    "        data['cv_splits_mets'][f\"batch_{i}\"]=\"\"\n",
    "        data['cv_splits_mets'].loc[data['pheno'].index[train_idx],f\"batch_{i}\"]=\"train\"\n",
    "        data['cv_splits_mets'].loc[data['pheno'].index[test_idx],f\"batch_{i}\"]=\"test\"\n",
    "\n",
    "    for i,(train_idx,test_idx) in enumerate(list(ss.split(X=X,y=macro_annot,groups=patient))):\n",
    "        data['cv_splits_macro'][f\"batch_{i}\"]=\"\"\n",
    "        data['cv_splits_macro'].loc[data['pheno'].index[train_idx],f\"batch_{i}\"]=\"train\"\n",
    "        data['cv_splits_macro'].loc[data['pheno'].index[test_idx],f\"batch_{i}\"]=\"test\"\n",
    "\n",
    "    for i,(train_idx,test_idx) in enumerate(list(ss.split(X=X,y=macro_annot,groups=batch))):\n",
    "        data['cv_splits_macro_batch'][f\"batch_{i}\"]=\"\"\n",
    "        data['cv_splits_macro_batch'].loc[data['pheno'].index[train_idx],f\"batch_{i}\"]=\"train\"\n",
    "        data['cv_splits_macro_batch'].loc[data['pheno'].index[test_idx],f\"batch_{i}\"]=\"test\"\n",
    "\n",
    "    ss=StratifiedShuffleSplit(n_splits=10, random_state=42, test_size=None,\n",
    "                train_size=0.7)\n",
    "    data['cv_splits_mets_stratified_shuffle']=pd.DataFrame(index=data['pheno'].index)\n",
    "    data['cv_splits_macro_stratified_shuffle']=pd.DataFrame(index=data['pheno'].index)\n",
    "    data['cv_splits_macro_batch_stratified_shuffle']=pd.DataFrame(index=data['pheno'].index)\n",
    "\n",
    "    for i,(train_idx,test_idx) in enumerate(list(ss.split(X=X,y=any_mets,groups=batch))):\n",
    "        data['cv_splits_mets_stratified_shuffle'][f\"batch_{i}\"]=\"\"\n",
    "        data['cv_splits_mets_stratified_shuffle'].loc[data['pheno'].index[train_idx],f\"batch_{i}\"]=\"train\"\n",
    "        data['cv_splits_mets_stratified_shuffle'].loc[data['pheno'].index[test_idx],f\"batch_{i}\"]=\"test\"\n",
    "\n",
    "    for i,(train_idx,test_idx) in enumerate(list(ss.split(X=X,y=macro_annot,groups=patient))):\n",
    "        data['cv_splits_macro_stratified_shuffle'][f\"batch_{i}\"]=\"\"\n",
    "        data['cv_splits_macro_stratified_shuffle'].loc[data['pheno'].index[train_idx],f\"batch_{i}\"]=\"train\"\n",
    "        data['cv_splits_macro_stratified_shuffle'].loc[data['pheno'].index[test_idx],f\"batch_{i}\"]=\"test\"\n",
    "\n",
    "    for i,(train_idx,test_idx) in enumerate(list(ss.split(X=X,y=macro_annot,groups=batch))):\n",
    "        data['cv_splits_macro_batch_stratified_shuffle'][f\"batch_{i}\"]=\"\"\n",
    "        data['cv_splits_macro_batch_stratified_shuffle'].loc[data['pheno'].index[train_idx],f\"batch_{i}\"]=\"train\"\n",
    "        data['cv_splits_macro_batch_stratified_shuffle'].loc[data['pheno'].index[test_idx],f\"batch_{i}\"]=\"test\"\n",
    "    final_data[k]=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(final_data,open('../../data/cv_split_data_final.pkl','wb'))\n",
    "# final touches on datasets (e.g., scaling of age) produced final_splits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
